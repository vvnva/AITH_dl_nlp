{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d932b8",
   "metadata": {},
   "source": [
    "# Разметка lenta-ru с помощью deeppavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eae703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from corus import load_lenta\n",
    "from deeppavlov import build_model\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e3bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -L https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz -o data/lenta-ru-news.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8660f9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 12:24:21.705 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/v1/ner/ner_rus_bert_coll3_torch.tar.gz download because of matching hashes\n",
      "c:\\Users\\verai\\projects\\AITH_dl_nlp\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "ner_model = build_model('ner_collection3_bert', download=True, install=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "688d048c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Египетский перевозчик EgyptAir сообщил о возмо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Глава Красногорского района Московской области...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Депутат Виталий Милонов внес в Госдуму законоп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Верховный суд Индии разрешил женщинам в фертил...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Россиянам не стоит бояться роста цен на хлеб —...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Египетский перевозчик EgyptAir сообщил о возмо...\n",
       "1  Глава Красногорского района Московской области...\n",
       "2  Депутат Виталий Милонов внес в Госдуму законоп...\n",
       "3  Верховный суд Индии разрешил женщинам в фертил...\n",
       "4  Россиянам не стоит бояться роста цен на хлеб —..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = load_lenta('data/lenta-ru-news.csv.gz')\n",
    "data = pd.DataFrame(records)\n",
    "data.columns = ['url', 'title', 'text', 'topic', 'tags', 'date']\n",
    "data = data.sample(n=10000, random_state=random_state)\n",
    "data = data[['text']].reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d33fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Египетский', 'перевозчик', 'EgyptAir', 'сообщил', 'о', 'возможном', 'повышении', 'стоимости', 'билетов', 'на', 'свои', 'международные', 'рейсы', 'из', '‑', 'за', 'девальвации', 'национальной', 'валюты.', 'Такое', 'заявление', 'сделал', 'генеральный', 'директор', 'перевозчика', 'Шериф', 'Фатхи', ',', 'его', 'слова', 'приводит', '«', 'Рамблер.Путешествия', '»', '.', 'Фатхи', 'заверил', ',', 'что', 'пока', 'компания', 'не', 'приняла', 'решение', ',', 'но', 'признал', ',', 'что', '«', 'рост', 'неизбежен', '»', '.', 'При', 'этом', ',', 'пока', 'тарифы', 'на', 'перевозку', 'обсуждаются', ',', 'на', 'сайте', 'авиакомпании', 'билеты', 'уже', 'подорожали.', 'В', 'руководстве', 'авиакомпании', 'это', 'объяснили', 'изменением', 'в', 'налогообложении.', 'Предполагается', ',', 'что', 'повышение', 'цен', 'коснется', 'только', 'международных', 'перелетов', ',', 'стоимость', 'внутренних', 'рейсов', 'останется', 'прежней.', 'Отмечается', ',', 'что', 'центральный', 'банк', 'Египта', 'девальвировал', 'национальную', 'валюту', 'в', 'понедельник', ',', '14', 'марта', ',', 'на', '13', 'процентов', '—', 'с', '7,73', 'до', '8,85', 'египетского', 'фунта', 'за', 'доллар.', 'Ранее', 'сообщалось', ',', 'что', 'министр', 'иностранных', 'дел', 'Египта', 'заявил', ',', 'что', 'в', 'аэропортах', 'Каира', ',', 'Шарм', '-', 'эль', '-', 'Шейха', 'и', 'Хургады', 'были', 'введены', 'новые', 'меры', 'безопасности', ',', 'которые', 'рекомендовали', 'российские', 'эксперты.', 'Указ', 'о', 'приостановке', 'полетов', 'из', 'России', 'в', 'Египет', 'президент', 'России', 'Владимир', 'Путин', 'подписал', '8', 'ноября.', 'Это', 'произошло', 'после', 'катастрофы', 'самолета', 'Airbus', 'A321', 'компании', '«', 'Когалымавиа', '»', ',', 'летевшего', 'из', 'Шарм', '-', 'эль', '-', 'Шейха', 'в', 'Санкт', '-', 'Петербург.', 'Лайнер', 'разбился', '31', 'октября.', 'Все', '224', 'человека', '(', 'в', 'основном', 'россияне', ')', ',', 'находившиеся', 'на', 'борту', ',', 'погибли.', 'Ответственность', 'за', 'катастрофу', 'взяли', 'на', 'себя', 'боевики', 'группировки', '«', 'Вилайят', 'Синай', '»', ',', 'присягнувшей', 'на', 'верность', 'запрещенной', 'в', 'России', 'террористической', 'организации', '«', 'Исламское', 'государство', '»', '.', 'На', 'совещании', 'в', 'Кремле', '16', 'ноября', 'глава', 'ФСБ', 'Александр', 'Бортников', 'заявил', ',', 'что', 'причиной', 'катастрофы', 'стал', 'теракт']], [['O', 'O', 'S-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'E-PER', 'O', 'O', 'O', 'O', 'O', 'S-ORG', 'O', 'O', 'S-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-LOC', 'O', 'O', 'O', 'O', 'O', 'S-LOC', 'O', 'S-LOC', 'S-LOC', 'S-LOC', 'S-LOC', 'S-LOC', 'O', 'S-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-LOC', 'O', 'S-LOC', 'O', 'S-LOC', 'B-PER', 'E-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-ORG', 'O', 'O', 'O', 'O', 'S-LOC', 'S-LOC', 'S-LOC', 'S-LOC', 'S-LOC', 'O', 'S-LOC', 'S-LOC', 'S-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'E-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-LOC', 'O', 'O', 'O', 'B-ORG', 'E-ORG', 'O', 'O', 'O', 'O', 'O', 'S-LOC', 'O', 'O', 'O', 'S-ORG', 'B-PER', 'E-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]]\n"
     ]
    }
   ],
   "source": [
    "print(ner_model([data[\"text\"][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "304de1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_texts_by_token_count(text_list, pretrained_model, token_limit):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
    "    result_texts = []\n",
    "    for sentence in text_list:\n",
    "        tokenized = tokenizer.tokenize(sentence)\n",
    "        if len(tokenized) <= token_limit:\n",
    "            result_texts.append(sentence)\n",
    "    return result_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a52d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\verai\\projects\\AITH_dl_nlp\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "filtered_texts = select_texts_by_token_count(data['text'], \"DeepPavlov/rubert-base-cased\", 450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "920b5e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9713/9713 [04:53<00:00, 33.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Египетский', 'перевозчик', 'EgyptAir', 'сообщил', 'о', 'возможном', 'повышении', 'стоимости', 'билетов', 'на', 'свои', 'международные', 'рейсы', 'из', '‑', 'за', 'девальвации', 'национальной', 'валюты.', 'Такое', 'заявление', 'сделал', 'генеральный', 'директор', 'перевозчика', 'Шериф', 'Фатхи', ',', 'его', 'слова', 'приводит', '«', 'Рамблер.Путешествия', '»', '.', 'Фатхи', 'заверил', ',', 'что', 'пока', 'компания', 'не', 'приняла', 'решение', ',', 'но', 'признал', ',', 'что', '«', 'рост', 'неизбежен', '»', '.', 'При', 'этом', ',', 'пока', 'тарифы', 'на', 'перевозку', 'обсуждаются', ',', 'на', 'сайте', 'авиакомпании', 'билеты', 'уже', 'подорожали.', 'В', 'руководстве', 'авиакомпании', 'это', 'объяснили', 'изменением', 'в', 'налогообложении.', 'Предполагается', ',', 'что', 'повышение', 'цен', 'коснется', 'только', 'международных', 'перелетов', ',', 'стоимость', 'внутренних', 'рейсов', 'останется', 'прежней.', 'Отмечается', ',', 'что', 'центральный', 'банк', 'Египта', 'девальвировал', 'национальную', 'валюту', 'в', 'понедельник', ',', '14', 'марта', ',', 'на', '13', 'процентов', '—', 'с', '7,73', 'до', '8,85', 'египетского', 'фунта', 'за', 'доллар.', 'Ранее', 'сообщалось', ',', 'что', 'министр', 'иностранных', 'дел', 'Египта', 'заявил', ',', 'что', 'в', 'аэропортах', 'Каира', ',', 'Шарм', '-', 'эль', '-', 'Шейха', 'и', 'Хургады', 'были', 'введены', 'новые', 'меры', 'безопасности', ',', 'которые', 'рекомендовали', 'российские', 'эксперты.', 'Указ', 'о', 'приостановке', 'полетов', 'из', 'России', 'в', 'Египет', 'президент', 'России', 'Владимир', 'Путин', 'подписал', '8', 'ноября.', 'Это', 'произошло', 'после', 'катастрофы', 'самолета', 'Airbus', 'A321', 'компании', '«', 'Когалымавиа', '»', ',', 'летевшего', 'из', 'Шарм', '-', 'эль', '-', 'Шейха', 'в', 'Санкт', '-', 'Петербург.', 'Лайнер', 'разбился', '31', 'октября.', 'Все', '224', 'человека', '(', 'в', 'основном', 'россияне', ')', ',', 'находившиеся', 'на', 'борту', ',', 'погибли.', 'Ответственность', 'за', 'катастрофу', 'взяли', 'на', 'себя', 'боевики', 'группировки', '«', 'Вилайят', 'Синай', '»', ',', 'присягнувшей', 'на', 'верность', 'запрещенной', 'в', 'России', 'террористической', 'организации', '«', 'Исламское', 'государство', '»', '.', 'На', 'совещании', 'в', 'Кремле', '16', 'ноября', 'глава', 'ФСБ', 'Александр', 'Бортников', 'заявил', ',', 'что', 'причиной', 'катастрофы', 'стал', 'теракт']], [['O', 'O', 'S-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'E-PER', 'O', 'O', 'O', 'O', 'O', 'S-ORG', 'O', 'O', 'S-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-LOC', 'O', 'O', 'O', 'O', 'O', 'S-LOC', 'O', 'S-LOC', 'S-LOC', 'S-LOC', 'S-LOC', 'S-LOC', 'O', 'S-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-LOC', 'O', 'S-LOC', 'O', 'S-LOC', 'B-PER', 'E-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-ORG', 'O', 'O', 'O', 'O', 'S-LOC', 'S-LOC', 'S-LOC', 'S-LOC', 'S-LOC', 'O', 'S-LOC', 'S-LOC', 'S-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'E-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-LOC', 'O', 'O', 'O', 'B-ORG', 'E-ORG', 'O', 'O', 'O', 'O', 'O', 'S-LOC', 'O', 'O', 'O', 'S-ORG', 'B-PER', 'E-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "synthetic_annots = [ner_model([text]) for text in tqdm(filtered_texts)]\n",
    "print(synthetic_annots[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae3b619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_map = {\n",
    "    'S-LOC': 'B-LOC',\n",
    "    'E-LOC': 'I-LOC',\n",
    "    'S-ORG': 'B-ORG',\n",
    "    'E-ORG': 'I-ORG',\n",
    "    'S-PER': 'B-PER',\n",
    "    'E-PER': 'I-PER'\n",
    "}\n",
    "\n",
    "adjusted_annots = [[annot[0], [[tag_map.get(tag, tag) for tag in annot[1][0]]]] for annot in synthetic_annots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f33cc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальные BIO-теги после замены: {'I-LOC', 'I-ORG', 'B-ORG', 'B-PER', 'I-PER', 'B-LOC', 'O'}\n"
     ]
    }
   ],
   "source": [
    "# Уникальные теги с учётом замен\n",
    "unique_tags = {tag for annot in adjusted_annots for tag in annot[1][0]}\n",
    "print(\"Уникальные BIO-теги после замены:\", unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9da45e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем DataFrame с текстами и обновлённой синтетической разметкой\n",
    "df_annots = pd.DataFrame({\"text\": filtered_texts,\n",
    "                          \"annotation\": adjusted_annots})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0055b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем DataFrame в формате Parquet\n",
    "df_annots.to_parquet('data/synthetic_annotations.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
